{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cade614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Dense, ReLU, BatchNormalization, Input, Flatten, Concatenate, Reshape,\\\n",
    "Activation, Conv2DTranspose, LeakyReLU, Dropout\n",
    "from keras import Model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.metrics import Mean\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical, image_dataset_from_directory\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4efae0",
   "metadata": {},
   "source": [
    "## Load CelebA data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac61d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = 'celeba'\n",
    "IMG_SHAPE = (128, 128, 3)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888b6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def celeba_transform(x):\n",
    "    return ((tf.cast(x, tf.float32) - 127.5) / 127.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df7d4329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = image_dataset_from_directory('../data/input/celeba', \n",
    "                image_size=IMG_SHAPE[:-1], \n",
    "                batch_size=None,\n",
    "                labels=None,\n",
    "                smart_resize=True\n",
    "             )\\\n",
    "             .map(lambda x: celeba_transform(x))\\\n",
    "             .batch(batch_size, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "             .repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2803f1",
   "metadata": {},
   "source": [
    "## Define Conditional GAN model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "792ace33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGAN(keras.Model):\n",
    "    def __init__(self, n_critic, latent_dim=100, kernel_size=5):\n",
    "        super().__init__()\n",
    "        self.n_critic = n_critic\n",
    "        self.z_dim = latent_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.discriminator = self._build_discriminator()\n",
    "        self.generator = self._build_generator()\n",
    "        \n",
    "    def compile_model(self, discriminator_optimizer, generator_optimizer, loss_fn):\n",
    "        super().compile(run_eagerly=False)\n",
    "        self.discriminator_optimizer = discriminator_optimizer\n",
    "        self.generator_optimizer = generator_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "        self.discriminator_loss_metric = Mean(name='d_loss')\n",
    "        self.generator_loss_metric = Mean(name='g_loss')\n",
    "        \n",
    "    def _build_generator(self):\n",
    "        img = Input((self.z_dim,))\n",
    "        z = Dense(8*8*512)(img)\n",
    "        # z = BatchNormalization()(z)\n",
    "        z = LeakyReLU()(z)\n",
    "        \n",
    "        z = Reshape((8, 8, 512))(z)\n",
    "        \n",
    "        num_filters = [128, 128, 64, 32]\n",
    "        for f in num_filters:\n",
    "            z = Conv2DTranspose(\n",
    "                filters=f,\n",
    "                kernel_size=self.kernel_size,\n",
    "                strides=2,\n",
    "                padding='same',\n",
    "            )(z)\n",
    "            # z = BatchNormalization()(z)\n",
    "            z = LeakyReLU(alpha=0.2)(z)\n",
    "        \n",
    "        output = Conv2D(\n",
    "            filters=3,\n",
    "            kernel_size=5,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            activation='tanh',\n",
    "        )(z)\n",
    "\n",
    "        return Model(inputs=img, outputs=output)\n",
    "    \n",
    "    def _build_discriminator(self):\n",
    "        img = Input(IMG_SHAPE)\n",
    "        \n",
    "        z = Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=self.kernel_size,\n",
    "            strides=2,\n",
    "            padding='same',\n",
    "        )(img)\n",
    "        z = LeakyReLU()(z)\n",
    "        \n",
    "        z = Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=self.kernel_size,\n",
    "            strides=2,\n",
    "            padding='same',\n",
    "        )(z)\n",
    "        z = LeakyReLU()(z)\n",
    "        \n",
    "        z = Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=self.kernel_size,\n",
    "            strides=2,\n",
    "            padding='same',\n",
    "        )(z)\n",
    "        z = LeakyReLU()(z)\n",
    "        \n",
    "#         z = Conv2D(\n",
    "#             filters=256,\n",
    "#             kernel_size=self.kernel_size,\n",
    "#             strides=2,\n",
    "#             padding='same',\n",
    "#         )(z)\n",
    "#         z = LeakyReLU()(z)\n",
    "        \n",
    "#         z = Conv2D(\n",
    "#             filters=512,\n",
    "#             kernel_size=5,\n",
    "#             strides=2,\n",
    "#             padding='same',\n",
    "#         )(z)\n",
    "#         z = LeakyReLU()(z)\n",
    "        \n",
    "        z = Flatten()(z)\n",
    "        z = Dropout(0.3)(z)\n",
    "        output = Dense(1)(z)\n",
    "        \n",
    "        return Model(inputs=img, outputs=output)\n",
    "    \n",
    "    def train_step(self, batch_data):\n",
    "        img = batch_data\n",
    "        batch_size = batch_data.shape[0]\n",
    "        real_target_labels = tf.ones((batch_size, 1))\n",
    "        fake_target_labels = -1.0 * tf.ones((batch_size, 1))\n",
    "        \n",
    "        # Discriminator Loss\n",
    "        for _ in range(self.n_critic):\n",
    "            with tf.GradientTape() as tape:\n",
    "                z = tf.random.normal((batch_size, self.z_dim))\n",
    "                fake_img = self.generator(z)\n",
    "                combined_img = tf.concat([img, fake_img], axis=0)\n",
    "                labels = tf.concat([real_target_labels, fake_target_labels], axis=0)\n",
    "                predictions = self.discriminator(combined_img)\n",
    "                d_loss = 0.5*self.loss_fn(labels, predictions)\n",
    "            \n",
    "                d_loss = d_loss + 2*self.gp_loss(img, fake_img)\n",
    "                \n",
    "            gradients = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "            self.discriminator_optimizer.apply_gradients(zip(gradients, self.discriminator.trainable_weights))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generator Loss\n",
    "            z = tf.random.normal((batch_size, self.z_dim))\n",
    "            fake_img = self.generator(z)\n",
    "            fake_predictions = self.discriminator(fake_img)\n",
    "            g_loss = self.loss_fn(real_target_labels, fake_predictions)\n",
    "            \n",
    "        gradients = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.generator_optimizer.apply_gradients(zip(gradients, self.generator.trainable_weights))\n",
    "        \n",
    "        self.discriminator_loss_metric.update_state(d_loss)\n",
    "        self.generator_loss_metric.update_state(g_loss)\n",
    "        \n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.discriminator_loss_metric, self.generator_loss_metric]\n",
    "    \n",
    "    def gp_loss(self, real_img, fake_img):\n",
    "        try:\n",
    "            alpha = tf.random.uniform(fake_img.shape, 0.0, 1.0)\n",
    "            interpolated_img = alpha * real_img + (1-alpha) * fake_img\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(interpolated_img)\n",
    "                predictions = self.discriminator(interpolated_img)\n",
    "\n",
    "            gradients = tape.gradient(predictions, [interpolated_img])\n",
    "            gradient_l2_norm = K.sqrt(K.sum(K.square(gradients), axis=[1, 2, 3]))\n",
    "\n",
    "            gradient_penalty = K.mean(K.square(1.0-gradient_l2_norm))\n",
    "            return gradient_penalty\n",
    "        except Exception as e:\n",
    "            print(real_img.shape, fake_img.shape)\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee0ea3",
   "metadata": {},
   "source": [
    "## Define Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20341f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super().__init__()\n",
    "        self.z_dim = latent_dim\n",
    "        self.z = tf.random.normal((10, 10, self.z_dim))\n",
    "        self.labels = tf.keras.utils.to_categorical(np.arange(10), num_classes=10, dtype=np.float32)\n",
    "        \n",
    "    def on_train_begin(self, logs):\n",
    "        self.d_losses = []\n",
    "        self.g_losses = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.d_losses.append(logs['d_loss'])\n",
    "        self.g_losses.append(logs['g_loss'])\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        fig, ax = plt.subplots(10, 10, figsize=(20, 20))\n",
    "        for i in range(10):\n",
    "            generated_faces = self.model.generator(self.z[i], training=False)\n",
    "            for j in range(10):\n",
    "                ax[i][j].matshow(np.clip(generated_faces[j]*127.5 + 127.5, 0, 255).astype(int), cmap='viridis')\n",
    "                ax[i][j].axis('off')\n",
    "        fig.savefig(f\"../data/tmp/celeba/generated_faces_{epoch:03}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "        ax.plot(self.d_losses, label='Discriminator loss')\n",
    "        ax.plot(self.g_losses, label='Generator loss')\n",
    "        ax.legend()\n",
    "        fig.savefig(f\"../data/tmp/celeba/training_losses.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    def on_train_end(self, logs):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "        ax.plot(self.d_losses, label='Discriminator loss')\n",
    "        ax.plot(self.g_losses, label='Generator loss')\n",
    "        ax.legend()\n",
    "        fig.savefig(f\"../data/tmp/celeba/training_losses.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aeeb6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = CustomCallback(latent_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8d8f7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return - K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6d0180",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9f9991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "generator_lr = 1e-4\n",
    "discriminator_lr = 5e-5\n",
    "\n",
    "generator_optimizer = Adam(learning_rate=generator_lr)\n",
    "discriminator_optimizer = Adam(learning_rate=discriminator_lr)\n",
    "\n",
    "loss_fn = wasserstein_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2908e8c",
   "metadata": {},
   "source": [
    "## Define a Data Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b25a744",
   "metadata": {},
   "source": [
    "## Train CGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d8cdf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "n_critic = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dfc80135",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgan = CGAN(n_critic=n_critic, latent_dim=latent_dim, kernel_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e6f798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgan.compile_model(discriminator_optimizer, generator_optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda98eb",
   "metadata": {},
   "source": [
    "## GAN Training Hacks (https://github.com/soumith/ganhacks)\n",
    "\n",
    "### Tracking failures early\n",
    "- D loss goes to 0: failure mode\n",
    "- check norms of gradients: if they are over 100 things are screwing up\n",
    "- when things are working, D loss has low variance and goes down over time vs having huge variance and spiking\n",
    "- if loss of generator steadily decreases, then it's fooling D with garbage (says martin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba0d11c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   6/1000 [..............................] - ETA: 2:16 - d_loss: 0.3141 - g_loss: -0.0033 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0244s vs `on_train_batch_end` time: 0.0969s). Check your callbacks.\n",
      "1000/1000 [==============================] - 135s 133ms/step - d_loss: -6.8937 - g_loss: 1.7878\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 136s 136ms/step - d_loss: -2.2474 - g_loss: 4.3519\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 139s 139ms/step - d_loss: -1.9945 - g_loss: -6.7801\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 137s 137ms/step - d_loss: -1.7611 - g_loss: -15.6615\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 144s 143ms/step - d_loss: -1.5285 - g_loss: -25.4170\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 135s 134ms/step - d_loss: -1.4238 - g_loss: -23.4614\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 132s 132ms/step - d_loss: -1.0932 - g_loss: -14.1976\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 137s 137ms/step - d_loss: -1.0946 - g_loss: -11.0348\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 132s 132ms/step - d_loss: -0.9222 - g_loss: -16.9638\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 131s 130ms/step - d_loss: -1.1996 - g_loss: -20.3411\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 135s 135ms/step - d_loss: -0.8637 - g_loss: -16.2758\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 145s 145ms/step - d_loss: -1.0007 - g_loss: 12.9810\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 134s 134ms/step - d_loss: -0.6142 - g_loss: 0.3645\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 132s 132ms/step - d_loss: -0.6166 - g_loss: -0.5932\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 131s 131ms/step - d_loss: -1.0938 - g_loss: -11.9038\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 134s 133ms/step - d_loss: -0.7611 - g_loss: -13.7369\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 139s 139ms/step - d_loss: -0.6742 - g_loss: -30.2342\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 135s 134ms/step - d_loss: -0.5705 - g_loss: -10.0669\n",
      "Epoch 19/20\n",
      " 863/1000 [========================>.....] - ETA: 18s - d_loss: -0.5710 - g_loss: -41.8682"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cgan.fit(train_data,\n",
    "             epochs=epochs,\n",
    "             steps_per_epoch=1000,\n",
    "             callbacks=[callback],\n",
    "             use_multiprocessing = True\n",
    "            )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    callback.on_train_end(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ac8e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10, 10, figsize=(20, 20))\n",
    "for i in range(10):\n",
    "    z = tf.random.normal((10, latent_dim))\n",
    "    generated_faces = cgan.generator(z)\n",
    "    for j in range(10):\n",
    "        ax[i][j].imshow(np.clip(generated_faces[j]*127.5 + 127.5, 0, 255).astype(int))\n",
    "        ax[i][j].axis('off')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_summary():\n",
    "    print(f\"celeba_lr_g_{generator_lr}_d_{discriminator_lr}_epochs_{epochs}_n_critic_{n_critic}_bs_{batch_size}\")\n",
    "    print(f\"Generator learning rate: {generator_lr}\")\n",
    "    print(f\"Discriminator learning rate: {discriminator_lr}\")\n",
    "    print()\n",
    "    print(f\"Number of epochs: {epochs}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print()\n",
    "    print(f\"n_critic: {n_critic}\")\n",
    "    print()\n",
    "    print(f\"Generator summary:\")\n",
    "    print(cgan.generator.summary())\n",
    "    print()\n",
    "    print(f\"Discriminator summary:\")\n",
    "    print(cgan.discriminator.summary())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_model_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
